Architecture Overview

  Your project uses a provider abstraction layer that allows you to support multiple AI providers (Claude, OpenAI, etc.) through a unified interface. Think
   of it as a plugin system for AI services.

  Core Structure

  services/ai/
  â”œâ”€â”€ providers/
  â”‚   â”œâ”€â”€ IAIProvider.ts          # The contract all providers must implement
  â”‚   â”œâ”€â”€ factory.ts              # Creates and caches provider instances
  â”‚   â”œâ”€â”€ claude/                 # Claude implementation (COMPLETE âœ…)
  â”‚   â”‚   â”œâ”€â”€ ClaudeProvider.ts
  â”‚   â”‚   â”œâ”€â”€ ClaudeStreamHandler.ts
  â”‚   â”‚   â””â”€â”€ ClaudeErrorMapper.ts
  â”‚   â””â”€â”€ utils/                  # Shared resilience utilities
  â”‚       â”œâ”€â”€ rate-limit/         # Auto-retry with exponential backoff
  â”‚       â”œâ”€â”€ circuit-breaker/    # Prevent cascading failures
  â”‚       â”œâ”€â”€ error-logging/      # Structured error tracking
  â”‚       â””â”€â”€ system-prompts/     # Prompt management with presets

  ---
  How Providers Work

  1. The Interface (IAIProvider)

  Every provider must implement these core methods:
  - sendMessage() - Send a message and get a response
  - streamMessage() - Get streaming responses with callbacks
  - getAvailableModels() - List supported models
  - testConnection() - Health check
  - estimateCost() - Calculate usage costs

  This ensures all providers work the same way from the application's perspective.

  2. The Factory Pattern

  Instead of creating providers directly, you use AIProviderFactory:

  // Get the singleton factory
  const factory = AIProviderFactory.getInstance();

  // Create a provider (automatically cached)
  const provider = factory.createProvider(ProviderType.CLAUDE, config);

  // Now use it
  const response = await provider.sendMessage({...});

  Benefits:
  - Instance caching - Same config = same instance (saves memory)
  - Centralized management - One place to create/destroy providers
  - Dynamic registration - Add new providers at runtime

  3. Provider Utilities (The Secret Sauce)

  Each provider is wrapped with 4 resilience utilities that make it production-ready:

  ğŸ”„ RateLimitManager

  - Automatically retries when you hit rate limits (429 errors)
  - Uses exponential backoff: 1s â†’ 2s â†’ 4s â†’ 8s â†’ 16s â†’ 30s
  - Parses provider-specific headers to know when to retry

  ğŸ›¡ï¸ CircuitBreakerManager

  - Prevents cascading failures
  - After 5 failures, opens the circuit (fails fast)
  - Auto-recovers after 60 seconds to test if service is back

  ğŸ“Š ErrorLogger

  - Tracks all errors in a circular buffer (last 1000 errors)
  - Categorizes by type, severity, provider
  - Provides statistics for monitoring

  ğŸ“ SystemPromptManager

  - 6 built-in presets (assistant, coding, creative, etc.)
  - Validates and sanitizes system prompts
  - Estimates token usage

  ---
  Message Flow Example

  When you send a message, here's what happens:

  1. Application calls provider.sendMessage()
                  â†“
  2. CircuitBreaker checks state (is service healthy?)
                  â†“
  3. RateLimitManager wraps the API call
                  â†“
  4. Claude API is called
                  â†“
  5. If 429 error â†’ RateLimitManager retries with backoff
     If other error â†’ ClaudeErrorMapper converts to ProviderError
                  â†“
  6. Response is converted to unified AIResponse format
                  â†“
  7. Tokens counted, cost calculated
                  â†“
  8. ErrorLogger tracks any errors
                  â†“
  9. Return unified response to application

  ---
  Currently Implemented

  âœ… Claude Provider (COMPLETE)

  Located in: providers/claude/

  Features:
  - 3 models: Sonnet 4.5 (recommended), Haiku 4.5 (economy), Opus 4.1 (premium)
  - Streaming support with real-time callbacks
  - Vision capabilities
  - Cost tracking (tokens Ã— model pricing)
  - All utilities integrated

  Test Coverage: 17 integration tests passing

  â³ OpenAI Provider (PLANNED - VBT-44)

  Not yet implemented, but the architecture is ready:
  - Rate limit header parser already exists
  - Just needs implementation following the same pattern

  ---
  Key Design Benefits

  1. Provider Agnostic - Switch between Claude/OpenAI without changing application code
  2. Resilient - Auto-retry, circuit breaking, error logging built-in
  3. Testable - 770+ unit tests for utilities
  4. Extensible - Add new providers by implementing IAIProvider
  5. Cost Aware - Every interaction tracks tokens and cost
  6. Production Ready - Handles rate limits, failures, and monitoring

  ---
  Looking at Your Code

  I noticed in message.service.ts:712 there's likely integration with this provider system. The file structure shows:
  - âœ… Claude provider fully implemented and tested
  - âœ… Provider abstraction layer complete (VBT-42)
  - âœ… WebSocket integration for streaming (VBT-39)